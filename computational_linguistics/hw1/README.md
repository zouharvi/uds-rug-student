## Intro & Structure

The assginments are done in Jupyter Notebooks. Running the cells after each other should produce example outputs. The notebooks are also provided as exported PDFs. The outputs are however non-reproducible by seeds (though if you run the code enough times, by the law of large numbers, you will one day get the same output).

The code assumes that the data is stored in a folder `data` above this one, accessible by `../data/ads.txt`. In task two, I also used two other datasets. Links are provided in the notebook. The last section in the second assignment may take a few seconds to complete.

Included files:

```
README.md
ngram.py

zipfs_law.ipynb
text_generation.ipynb
statistical_dependence.ipynb

zipfs_law.pdf
text_generation.pdf
statistical_dependence.pdf
```

## Extra points

I would wish to claim some extra points for doing both the second and the third assignment and also working with reverse n-grams, multiple external datasets, lowercasing (and case restoration) and creating and switching ngram model in the second assignment.

## Results

The best result is the last generated snippet from the text generation task:

```
The same way again.
I will go to bed.

Discover the magic of the earth
for some people are still in it.
```