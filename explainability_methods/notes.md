# attention
- two years _before_ Attention Is All You Need
- introduction to _global_ and _local_ attention
- 8/10, interesting, yet easy

# LIME
- motivation for explainability
- introduction to their explainer system, which can be used also for 
- 7/10, interesting, slightly difficult

# SHAP
- ensemble for explainer systems
- 6/10, less interesting, slightly difficult

# LRP theory
- introduction to relevance propagation
- 6/10, interesting, difficult

# LRP application
- word significance/contribution
- 6/10, interesting, long

# Sensitivity Analysis, Activation Maximization
- 3/10, graphics

# Sensitivity Analysis, Application
- mystery
- 3/10

# Deconvolution and Pertrubation
- 3/10, graphics

# Text Deconvolution
- visualization of detected linguistic information
- 6/10

# Meaningful Pertrubation
- 3/10, graphics
